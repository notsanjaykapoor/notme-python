#!/usr/bin/env python

import os
import sys

sys.path.insert(1, os.path.join(sys.path[0], ".."))

import airflow.providers.postgres.hooks.postgres
import airflow.providers.postgres.operators.postgres
import psycopg2.extras  # noqa: E402
import sqlalchemy.engine  # noqa: E402
import sqlalchemy.engine.reflection  # noqa: E402
import sqlalchemy.inspection  # noqa: E402
import typer  # noqa: E402

import dot_init  # noqa: E402, F401

app = typer.Typer()


@app.command()
def test():
    # airflow postgres_conn is inferred from AIRFLOW_CONN_xxx
    os.environ["AIRFLOW_CONN_POSTGRES_CONN"] = os.environ.get("DATABASE_PEREGRINE_URL")

    pg_hook = airflow.providers.postgres.hooks.postgres.PostgresHook(postgres_conn_id="postgres_conn")
    # pg_engine: sqlalchemy.engine.Engine = pg_hook.get_sqlalchemy_engine()
    # pg_inspector: sqlalchemy.engine.reflection.Inspector = sqlalchemy.inspection.inspect(pg_engine)

    # schema_names: List[str] = pg_inspector.get_schema_names()

    # table_names: List[str] = pg_inspector.get_table_names(schema=POSTGRES_SCHEMA)
    # print(table_names)

    # get_all_objects = airflow.providers.postgres.operators.postgres.PostgresOperator(
    #     task_id="get_all_objects",
    #     postgres_conn_id="postgres_default",
    #     sql="SELECT * FROM public.integrations.integrations_batch;",
    # )

    # pg_conn = psycopg2.connect(os.environ.get("DATABASE_PEREGRINE_URL"))
    pg_conn = pg_hook.get_conn()

    cursor = pg_conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
    cursor.execute("select * from integrations_batch;")
    objects = cursor.fetchall()

    for object in objects:
        print(object)


if __name__ == "__main__":
    app()
